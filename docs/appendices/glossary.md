# Glossary of Terms - Physical AI & Humanoid Robotics

## A

**Action (ROS 2)**: A communication pattern in ROS 2 that handles long-running tasks with feedback, goal, and result messages.

**AI-Robot Brain**: The cognitive system of a robot that processes information, makes decisions, and plans actions using artificial intelligence.

**Artificial Intelligence (AI)**: The simulation of human intelligence processes by machines, especially computer systems, including learning, reasoning, and self-correction.

**Autonomous System**: A system that operates independently without human intervention, making decisions based on its programming and environmental inputs.

## B

**Behavior Tree**: A hierarchical structure used in AI for controlling robot behavior, organizing tasks in a tree-like structure with nodes representing actions and conditions.

**Bias in AI**: Systematic errors in AI systems that lead to unfair or inaccurate outcomes, often reflecting prejudices in training data or algorithm design.

**Black Box AI**: AI systems whose internal decision-making processes are not transparent or explainable to humans.

## C

**Cognitive Architecture**: The structural design of an AI system's mind, including its components and their relationships, governing how it processes information.

**Computer Vision**: A field of AI that enables computers to interpret and understand visual information from the world.

**Control Theory**: The mathematical study of how systems respond to inputs and how to maintain desired behaviors, fundamental to robotics.

**Cyber-Physical System**: A system that integrates computation, networking, and physical processes, common in robotics applications.

## D

**Deep Learning**: A subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns.

**Digital Twin**: A virtual replica of a physical object, system, or process that can be used for simulation, analysis, and optimization.

**Domain Randomization**: A technique in simulation where environment parameters are randomly varied to improve the transfer of learned behaviors from simulation to reality.

## E

**Embodied AI**: Artificial intelligence that is integrated into physical systems (robots) and interacts with the physical world.

**Embodiment**: The physical form of an AI system that enables interaction with the physical environment.

**Ethical AI**: AI systems designed and implemented with consideration for ethical principles, fairness, and human values.

**Explainable AI (XAI)**: AI systems that can explain their reasoning and decision-making processes in human-understandable terms.

## F

**Fail-Safe**: A design principle ensuring that a system defaults to a safe state when failure occurs.

**Feedback Control**: A control system that uses feedback from sensors to adjust robot behavior and maintain desired performance.

**Field Robot**: A robot designed to operate in unstructured, outdoor environments such as agriculture, construction, or exploration.

## G

**Gazebo**: A 3D simulation environment used for robotics that provides accurate physics simulation and rendering capabilities.

**GPU Acceleration**: The use of graphics processing units to accelerate computation, particularly important for AI and computer vision tasks.

**Graph SLAM**: Simultaneous Localization and Mapping using graph-based optimization methods.

## H

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots, focusing on design and implementation of effective interfaces.

**Humanoid Robot**: A robot with a body structure similar to that of a human, typically including a head, torso, arms, and legs.

## I

**Imitation Learning**: A machine learning approach where an agent learns to perform tasks by observing and mimicking expert demonstrations.

**Isaac Sim**: NVIDIA's simulation environment for robotics, providing GPU-accelerated physics simulation and AI training capabilities.

**Isaac ROS**: NVIDIA's collection of ROS 2 packages that accelerate perception and navigation tasks using GPU acceleration.

**Inverse Kinematics (IK)**: The mathematical process of determining the joint parameters needed to position a robot's end effector at a desired location.

## J

**Joint Space**: The configuration space defined by the joint angles or positions of a robot manipulator.

## K

**Kinematics**: The study of motion without considering the forces that cause it, describing the geometric relationships in robotic systems.

**Kinodynamic Planning**: Motion planning that considers both kinematic and dynamic constraints of a robot system.

## L

**Large Language Model (LLM)**: Advanced AI models trained on vast amounts of text data, capable of understanding and generating human-like text.

**Latent Space**: A lower-dimensional space that captures the essential features of high-dimensional data in machine learning models.

**Learning from Demonstration**: A robot learning method where the robot learns tasks by observing human demonstrations.

**LiDAR**: Light Detection and Ranging, a remote sensing method that uses light in the form of a pulsed laser to measure distances.

**Lifelong Learning**: The ability of AI systems to continuously learn and adapt throughout their operational lifetime.

## M

**Manipulator**: A robot arm designed to manipulate objects in the environment, typically with multiple degrees of freedom.

**Markov Decision Process (MDP)**: A mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision maker.

**Motion Planning**: The process of determining a collision-free path for a robot to move from a start to a goal configuration.

**Multimodal AI**: AI systems that can process and integrate information from multiple sensory modalities (e.g., vision, language, audio).

## N

**Navigation Stack (Nav2)**: The ROS 2 framework for robot navigation, providing tools for path planning, obstacle avoidance, and localization.

**Neural Network**: A computing system inspired by biological neural networks, used for machine learning and pattern recognition.

**Node (ROS 2)**: A process that performs computation in a ROS 2 system, typically implementing specific robot functionality.

## O

**Obstacle Avoidance**: The capability of a robot to detect and navigate around obstacles in its environment.

**OpenAI**: An artificial intelligence research laboratory that develops and researches AI technologies, including the GPT models.

**OpenRAVE**: An open-source robotics analysis and visualization environment for simulating robotic systems.

## P

**Path Planning**: The computational process of finding a valid path from a start to a goal position while avoiding obstacles.

**Perception System**: The components of a robot that process sensory information to understand the environment.

**PID Controller**: A control loop mechanism employing feedback that is widely used in robotics for precise control.

**Point Cloud**: A collection of data points in 3D space, typically generated by 3D scanners or LiDAR sensors.

**Probabilistic Robotics**: An approach to robotics that explicitly accounts for uncertainty in robot perception and action.

## Q

**Quaternion**: A mathematical representation used to describe 3D rotations and orientations, avoiding issues like gimbal lock.

## R

**RAG (Retrieval-Augmented Generation)**: An AI approach that combines information retrieval with language generation to produce more accurate and context-aware responses.

**Raspberry Pi**: A series of small, affordable single-board computers often used in robotics projects.

**Reinforcement Learning**: A type of machine learning where an agent learns to make decisions by receiving rewards or penalties.

**Robot Operating System (ROS)**: A flexible framework for writing robot software, providing services like hardware abstraction and message passing.

**ROS 2**: The second generation of the Robot Operating System with improved architecture for real-world applications.

**ROS 2 Distro**: A distribution of ROS 2, such as Humble Hawksbill, which includes specific versions of packages and dependencies.

**ROS 2 Middleware (RMW)**: The layer in ROS 2 that abstracts the underlying communication middleware (like DDS).

**ROS 2 Parameters**: Configuration values that can be set at runtime and adjusted without recompiling code.

**ROS Bridge**: A package that enables communication between ROS and web browsers using WebSockets.

**ROS Package**: A container for related ROS functionality, including executables, libraries, and configuration files.

**ROS TCP Connector**: A Unity package that enables communication between Unity and ROS using TCP/IP protocol.

**ROS Time**: The time system used in ROS, which can be simulated or real, allowing for consistent timing across distributed systems.

## S

**Safety-Critical System**: A system whose failure could result in loss of life, significant property damage, or environmental harm.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location.

**Service (ROS 2)**: A communication pattern in ROS 2 that provides synchronous request-response interactions between nodes.

**Simulation-to-Reality Transfer**: The process of transferring behaviors or models learned in simulation to real-world robotic systems.

**Social Robot**: A robot designed to interact with humans in a socially acceptable manner, often for companionship or assistance.

**State Estimation**: The process of estimating the internal state of a system from sensor measurements and control inputs.

**Supervised Learning**: A machine learning approach where models learn from labeled training data.

## T

**Teleoperation**: The remote control of a robot by a human operator, often with force feedback.

**Topic (ROS 2)**: A communication pattern in ROS 2 that enables asynchronous message passing between nodes.

**Trajectory Planning**: The process of creating a time-parameterized path that specifies the position, velocity, and acceleration of a robot over time.

**Transformer Model**: A deep learning architecture that uses attention mechanisms, fundamental to modern language models.

## U

**Unity**: A real-time 3D development platform that can be integrated with robotics for simulation and visualization.

**Unstructured Environment**: An environment that lacks fixed or predetermined organization, requiring robots to adapt to changing conditions.

## V

**Validation**: The process of verifying that a system meets its intended requirements and operates safely in its intended environment.

**Verification**: The process of checking that a system correctly implements a specific function according to its specifications.

**Vision-Language-Action (VLA)**: Systems that integrate visual perception, language understanding, and physical action capabilities.

**Visual Servoing**: A control method that uses visual feedback to control robot motion.

## W

**Whisper**: OpenAI's automatic speech recognition system designed for robust speech-to-text conversion.

**Whole-Body Control**: A control approach that considers the entire robot's dynamics when generating control commands.

## X

**Xenial**: Ubuntu 16.04 LTS, a version of Ubuntu that was supported for ROS 2 early releases.

## Y

**YAML**: A human-readable data serialization format commonly used for ROS configuration files.

## Z

**Zero-shot Learning**: The ability of AI systems to perform tasks they have not been explicitly trained on, based on general knowledge.

---

*This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics course. Terms are organized alphabetically for easy reference.*